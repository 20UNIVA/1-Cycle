{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9db2601f-376c-4ac3-b22d-0b8dc9c480fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "447b6852-55d1-4ddf-9713-35f19f4112c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '1cycle_2/clue_summary_result221014.json'\n",
    "with open(file,'r') as fr:\n",
    "    jdata = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10e9edf4-731c-419f-b10c-c3d1546378fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1011"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e6a5b36c-b6ce-4b38-8470-17bda47603a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Summary_bart import summary\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4000204b-078a-412c-b4fd-88556ed63b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class a:\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 5e-5\n",
    "    def learning_rate(self):\n",
    "        return self.learning_rate\n",
    "args = a()\n",
    "\n",
    "summary_model = summary(args)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('hyunwoongko/kobart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2cb69e95-3180-4d47-9d25-21c8a7f51508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_model.load_state_dict(torch.load('./summary/b16_lr5e-5/lightning_logs/version_1/checkpoints/checkpoints_epoch=84.ckpt')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d69c6b2-7d59-47b5-a987-63fc94910867",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d0481d2-2fc8-4815-b8c5-40255d9a7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:15<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "summary_model.model.eval().to(device)\n",
    "for i in tqdm(range(100)):\n",
    "    #random.seed(0)\n",
    "    result = jdata[i]['refine_data'] #data['sentences'][i][0]\n",
    "    # print('input:',result)\n",
    "    # print('--------------------')\n",
    "    # print('label: ',jdata[i]['summary'])\n",
    "    # print('--------------------')\n",
    "    inputs = result\n",
    "    #label_token = tokenizer(jdata[i]['summary'])['input_ids']\n",
    "    \n",
    "    #print(inputs)\n",
    "    batch = tokenizer(inputs, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    #print('length:',len(batch['input_ids'][0]))\n",
    "    len_sum = int(len(batch['input_ids'][0])*0.3)\n",
    "    #print(len_sum)\n",
    "    # print(batch['input_ids'].shape)\n",
    "    batch = batch.to(device)\n",
    "    generated_ids = summary_model.model.generate(batch['input_ids'],max_length=len_sum)#.squeeze().tolist()#, num_beams=2, max_length=1024)#, no_repeat_ngram_size=2)\n",
    "    result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    # print('--------------------')\n",
    "    # # print('len_output:',len(generated_ids[0]))\n",
    "    # print('output: ',result[0])\n",
    "    # print('--------------------')\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True, tokenizer = tokenizer)\n",
    "    scores = scorer.score(jdata[i]['summary'],result[0])\n",
    "    #print(scores)\n",
    "    # print(label_token)\n",
    "    # print(generated_ids)\n",
    "    score.append(scores['rougeL'][2]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "62b503e9-a7b3-462b-a0fd-053dc7e5b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.130070521025218\n"
     ]
    }
   ],
   "source": [
    "print(sum(score)/len(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "681899aa-ef7a-4e2d-9a79-07f78eb9eadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.09009009009009, 2.0338983050847457)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score), min(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9be5b174-e5b9-418c-bb4e-f4c9a642db75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'rouge-l f1 score'}>]], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARSElEQVR4nO3de5CddX3H8fengAis5e4WAjVYEU2hYlkvVafdCNUoeJsqF5EBhYnT0RaVjkanrTrWDs4otjq1LYrCdJBovRQEtaWULb06JGobECmoQYiYiEAgQNXAt3+cJ3UNG3dz9mxOfjnv18zOnt9zO9/feZ79nOf8zvMkqSokSe35hWEXIEnqjwEuSY0ywCWpUQa4JDXKAJekRhngktQoA1wjI8naJCdsY95eSb6QZGOSv93RtUn9MMClnlcC48CBVfWqJIckuSLJ95JUksVDrk96FANcCybJ7sOuYTs8AfifqtrctR8Bvgz8zvBK6kmPf6t6FA8KDVQ3TPG2JP8NPJBk9yQvTXJjknuTTCV56rTlK8mTprUvTvIn09pvTXJndyZ8zvTlk+yZ5P1JvptkfZK/SrJXHzW/G/hj4JQkm5KcXVXrq+ojwPVz3MbbkqxLcn+Sm5Mc303fLck7knyrm7c6yeHdvOckub4btrk+yXOmbW8qyXuT/BvwIPDEJE9JcnWSu7vnOHl7+6pdiwGuhXAacCKwH/BE4DLgTcDBwBeBLyR5zGwbSbIMeAtwAvAkYHKrRc4Hngwc281fRC+It0tVvRP4U+BTVTVWVRdtz/pJjgLeCDyjqh4HvBBY281+C73X48XALwKvAx5McgBwFfAh4EDgAuCqJAdO2/QZwHLgccAPgKuBTwKPB04FPpJkyfb2V7sOA1wL4UNVdXtVPQScAlxVVVdX1U+A9wN7Ac/5uVvoORn4RFXdWFUPAu/aMiNJ6IXbm6vq7qq6n14InzrgvszFw8CewJIke1TV2qr6VjfvHOAPq+rm6vmvqvohvTe4W6rqb6pqc1VdBnwTeMm07V7c9X0zsAxYW1Wf6Jb/GvBZ4FU7rJfa6RjgWgi3T3t8KHDblkZVPdLNXzSH7Ry61bamPz4Y2BtY3Q3N3EtvzPpggCRf6oZDNiU5va9ezFFV3UrvE8a7gA1JViY5tJt9OPCtGVb7mdelcxs/+7pM7+8TgGdt6WvX39OBX5p3B9QsA1wLYfo/cfk9euED/P+Z8+HAum7Sg/SCeIvpgXQncNi09uHTHt8FPAT8alXt1/3sW1VjAFX1om44ZKyqLp13j2ZRVZ+squfR62sB7+tm3Q78ygyr/Mzr0vllfvq6wM++jrcD/zytr/t1ffvdwfRALTLAtdA+DZyY5PgkewDnAT8C/r2b/3Xg1d2XfcuA39pq3dcmeWqSvYE/2jKjO5P/KPDBJI8HSLIoyQsHVXiSx9IbGgHYs2vPtNxRSZ6fZE/gf+m9sTzSzf4Y8J4kR3ZXk/xaN879ReDJSV7dfdF7CrAEuHIb5VzZLX9Gkj26n2dM/0JYo8cA14KqqpuB1wAfpnfW/BLgJVX1426Rc7tp99IbEvi7aet+id6XfNcCtwL/2c36Uff7bVumJ7kP+EfgqAGW/xCwqXv8za49kz3pfaF6F/B9el8yvr2bdwG9N6J/AO4DLgL26sbBT6L3hvZD4K3ASVV110xP0I3xv4DeGP/3uud5Hz99g9EIiv+hg1rRnW3eAOw57XptaWR5Bq6dWpJXdNd770/vjPMLhrfUY4BrZ/d6YAO9KzkeBvzSTuo4hCJJjfIMXJIatUP/saGDDjqoFi9e3Ne6DzzwAPvss89gC2qI/bf/9n90+7969eq7qurgrafv0ABfvHgxq1at6mvdqakpJicnB1tQQ+y//bf/k8MuY2iSbH3XLuAQiiQ1ywCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNWqH3omp/q1Zt5GzVlzV9/przz9xgNVI2hl4Bi5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSo2YN8CSHJ7k2yTeS3Jjk3G76AUmuTnJL93v/hS9XkrTFXM7ANwPnVdUS4NnAG5IsAVYA11TVkcA1XVuStIPMGuBVdWdVfbV7fD9wE7AIeBlwSbfYJcDLF6hGSdIMUlVzXzhZDFwHHA18t6r266YHuGdLe6t1lgPLAcbHx49buXJlX4Vu2rSJsbGxvtbdFWy4eyPrH+p//WMW7Tu4YoZg1Pe//R/t/i9dunR1VU1sPX33uW4gyRjwWeBNVXVfL7N7qqqSzPhOUFUXAhcCTExM1OTk5HaW3jM1NUW/6+4KPnzp5XxgzZx316OsPX1ycMUMwajvf/s/2v3fljldhZJkD3rhfWlVfa6bvD7JId38Q4ANC1OiJGkmc7kKJcBFwE1VdcG0WVcAZ3aPzwQuH3x5kqRtmctn8ucCZwBrkny9m/YO4Hzg00nOBm4DTl6QCiVJM5o1wKvqX4FsY/bxgy1HkjRX3okpSY0ywCWpUQa4JDWq/wuL1ZTFK66a1/przz9xQJVIGhTPwCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNmjXAk3w8yYYkN0yb9q4k65J8vft58cKWKUna2lzOwC8Gls0w/YNVdWz388XBliVJms2sAV5V1wF374BaJEnbIVU1+0LJYuDKqjq6a78LOAu4D1gFnFdV92xj3eXAcoDx8fHjVq5c2VehmzZtYmxsrK91dwUb7t7I+oeG9/zHLNp3eE+O+9/+j3b/ly5durqqJrae3m+AjwN3AQW8Bzikql4323YmJiZq1apV21l6z9TUFJOTk32tuyv48KWX84E1uw/t+deef+LQnhvc//Z/tPufZMYA7+sqlKpaX1UPV9UjwEeBZ863QEnS9ukrwJMcMq35CuCGbS0rSVoYs34mT3IZMAkclOQO4J3AZJJj6Q2hrAVev3AlSpJmMmuAV9VpM0y+aAFqkSRtB+/ElKRGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY3afdgFjIrFK66a1/rnHTOgQiTtMjwDl6RGGeCS1CgDXJIaZYBLUqMMcElq1KwBnuTjSTYkuWHatAOSXJ3klu73/gtbpiRpa3M5A78YWLbVtBXANVV1JHBN15Yk7UCzBnhVXQfcvdXklwGXdI8vAV4+2LIkSbNJVc2+ULIYuLKqju7a91bVft3jAPdsac+w7nJgOcD4+PhxK1eu7KvQTZs2MTY21te6O4M16zbOa/3xvWD9QwMqpkFH7Ltb0/t/vlo//udr1Pu/dOnS1VU1sfX0ed+JWVWVZJvvAlV1IXAhwMTERE1OTvb1PFNTU/S77s7grHnfibmZD6wZ3RtnL162T9P7f75aP/7na9T7vy39XoWyPskhAN3vDYMrSZI0F/0G+BXAmd3jM4HLB1OOJGmu5nIZ4WXAfwBHJbkjydnA+cBvJ7kFOKFrS5J2oFkHVavqtG3MOn7AtUiStoN3YkpSowxwSWqUAS5JjRrdC4u303z/Rx1JGjTPwCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVq92EXIM3FmnUbOWvFVX2vv/b8EwdYjbRz8AxckhplgEtSowxwSWqUAS5JjTLAJalR87oKJcla4H7gYWBzVU0MoihJ0uwGcRnh0qq6awDbkSRtB4dQJKlRqar+V06+A9wDFPDXVXXhDMssB5YDjI+PH7dy5cq+nmvTpk2MjY31Xet8rVm3cWjPDTC+F6x/aKglDNWw+3/Mon2H9+QM//gftlHv/9KlS1fPNEQ93wBfVFXrkjweuBr4vaq6blvLT0xM1KpVq/p6rqmpKSYnJ/srdAAWz+MuwEE475jNfGDN6N44O+z+D/tOzmEf/8M26v1PMmOAz2sIparWdb83AJ8Hnjmf7UmS5q7vAE+yT5LHbXkMvAC4YVCFSZJ+vvl8Jh0HPp9ky3Y+WVVfHkhVkqRZ9R3gVfVt4GkDrEWStB28jFCSGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUX3/r/StWbziqmGXoIbN9/hZe/6JA6pE+inPwCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNauZGnjXrNnKWN+NoRM33+PdGovnbGW/m8gxckhplgEtSowxwSWqUAS5JjTLAJalR8wrwJMuS3Jzk1iQrBlWUJGl2fQd4kt2AvwBeBCwBTkuyZFCFSZJ+vvmcgT8TuLWqvl1VPwZWAi8bTFmSpNmkqvpbMXklsKyqzunaZwDPqqo3brXccmB51zwKuLnPWg8C7upz3V2B/bf/9n90PaGqDt564oLfiVlVFwIXznc7SVZV1cQASmqS/bf/9n90+78t8xlCWQccPq19WDdNkrQDzCfArweOTHJEkscApwJXDKYsSdJs+h5CqarNSd4I/D2wG/DxqrpxYJU92ryHYRpn/0eb/dej9P0lpiRpuLwTU5IaZYBLUqOaCPBRu2U/yeFJrk3yjSQ3Jjm3m35AkquT3NL93n/YtS6kJLsl+VqSK7v2EUm+0h0Hn+q+PN8lJdkvyWeSfDPJTUl+Y5T2f5I3d8f+DUkuS/LYUdr/c7XTB/iI3rK/GTivqpYAzwbe0PV5BXBNVR0JXNO1d2XnAjdNa78P+GBVPQm4Bzh7KFXtGH8OfLmqngI8jd7rMBL7P8ki4PeBiao6mt5FEqcyWvt/Tnb6AGcEb9mvqjur6qvd4/vp/fEuotfvS7rFLgFePpQCd4AkhwEnAh/r2gGeD3ymW2SX7X+SfYHfBC4CqKofV9W9jND+p3eF3F5Jdgf2Bu5kRPb/9mghwBcBt09r39FNGwlJFgNPB74CjFfVnd2s7wPjw6prB/gz4K3AI137QODeqtrctXfl4+AI4AfAJ7ohpI8l2YcR2f9VtQ54P/BdesG9EVjN6Oz/OWshwEdWkjHgs8Cbquq+6fOqd/3nLnkNaJKTgA1VtXrYtQzJ7sCvA39ZVU8HHmCr4ZJdfP/vT+/TxhHAocA+wLKhFrWTaiHAR/KW/SR70AvvS6vqc93k9UkO6eYfAmwYVn0L7LnAS5OspTdk9nx6Y8L7dR+pYdc+Du4A7qiqr3Ttz9AL9FHZ/ycA36mqH1TVT4DP0TsmRmX/z1kLAT5yt+x3470XATdV1QXTZl0BnNk9PhO4fEfXtiNU1dur6rCqWkxvf/9TVZ0OXAu8sltsV+7/94HbkxzVTToe+AYjsv/pDZ08O8ne3d/Clv6PxP7fHk3ciZnkxfTGRLfcsv/e4Va0sJI8D/gXYA0/HQN+B71x8E8DvwzcBpxcVXcPpcgdJMkk8AdVdVKSJ9I7Iz8A+Brwmqr60RDLWzBJjqX3Be5jgG8Dr6V3wjUS+z/Ju4FT6F2R9TXgHHpj3iOx/+eqiQCXJD1aC0MokqQZGOCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUf8HfsLzefZ8mhYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'rouge-l f1 score':score})\n",
    "df.hist(bins=range(0,100,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4c145229-8a99-4acd-afea-7613810d5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge-l f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.383747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.873563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>11.204482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>14.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>12.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14.592275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>14.893617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7.055215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rouge-l f1 score\n",
       "17         10.383747\n",
       "20          7.083333\n",
       "21         12.873563\n",
       "46         11.204482\n",
       "50         14.285714\n",
       "66         14.795918\n",
       "68         12.068966\n",
       "71         14.592275\n",
       "84         14.893617\n",
       "88         12.676056\n",
       "92          2.033898\n",
       "96          7.055215"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rouge-l f1 score']<15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "93292899-2408-4e7e-a3d1-29f063b1fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: <h1>요 약</h1><p>전력시스템의 신뢰성을 보장하며 분산전원의 수용성을 높이기 위해 IEEE 1547 과 같은 표준을 개정하여 분산전원의 계통 연계기준을 강화하고 있다. 본 논문은 이러한 표준을 준수하는 IEEE 1547-2018기반의 스마트 인버터 기능의 제어 알고리즘을 제안하고, 스마트 인버터 기술의 검증을 위해 구축한 Power HiLS 기반의 테스트 플랫폼을 소개한다. 스마트 인버터 기능 중 Volt-var 제어와 Frequency-watt 제어 알고리즘은 상호운용성 표준을 준수하도록 해당 기능의 curve를 상위로부터 설정할 수 있도록 하며, 각 기능의 Enable 신호 시점을 상위 지령에 따라 제어할 수 있도록 하였다. 표준에 따라 Power HILS 테스트 플랫폼을 통해 Volt-var 제어와 Frequency-watt 제어에 대한 형식시험을 수행하였고, 명시된 표준 형식시험을 전부 만족함을 측정 결과를 통해 검증하였다. </p><h1>Ⅰ. 서론</h1><p>전 세계적으로 기후위기 극복을 위한 화셕연료 기반의 발전원 가동올 줄이고 재생에너지, ESS 등 분산자원의 보급률을 높이려는 옴직임이 활발하다. 특히, 우리 정부에서는 신재생에너지 수용률을 2030년까지 \\(20\\mathrm{\\%}\\), 2050년까지 최대 \\( 80 \\% \\) 수준으로 높이겠다는 로드맵을 제시하였다. 그러나. 전력시스템 운영 측면에서는 무분별한 분산전원의 증가에 따른 전력시스템의 신뢰성 및 안정도 하락을 심각하게 고려하고 있다.</p><p>전력시스템의 신뢰성을 보장함으로써 분산전원의 수용성을 향상하기 위해 미국에서는 IEEE 1547 개 같은 표준을 개정하여 분산전원의 계통연계기준을 강화하고, 지속적으로 요구사항을 업데이트하고 있다. 최근 IEEE 1547-2018 에서는 전력시스템과 분산자원간의 연계 기준 및 상호운용성 기술 사양에 대한 표준을 자세하게 제시하였으며, 이를 의무화하려는 시도가 늘어나고 있다. 이를 위해 표 1과 같이 데이터 모델, 연계요구사항, 시험 및 인증과 관련한 스마트 인버터 규정이 제정되었다</p><p>스마트 인버터는 계통의 안정화 지원을 위해 강화된 IEEE 계통 연계 기준과 DER Distributed Energy Resource) 표준을 만족하도록 필요 기능들을 탑재한 계통 연계형 인버터이다. 스마트인버터가 제공하는 다양한 계량연계 기능올 통해 분산전원의 간헐성과 변동성올 개선하며, 계통의 안정성과 복원성을 강화시킴으로써 전력 품질의 향상을 기대할 수 있다. 해외의 경우 분산자원의 안정성 증대를 위해 스마트인버터의 계통지원기능 보유 의무화를 추진 중에 있으며, 이러한 추세에 맞추어 국내에서도 스마트 인버터 계통지원 의무화가 필요한 상황이라고 판단한다.</p><p>이러한 스마트 인버터의 시험과 검증에 대하여 IEEE 1547.1-2020과 같이 해당 표준을 구체적으로 실험하고 검증할 수 있도록 규정화하였다. 이에 따라, 표준 만족여부 확인을 위한 테스트에 대해 정확하고 자동화 및 표준화 된 테스트 플랫폼을 개발하는 것에 대한 중요성도 강조되고 있다. 특히, 이러한 이슈에 맞추어 SunSpec Alliance에서는 통합 테스트 플랫폼을 위한 SunSpec SVP(System Validation Platform)를 개발하여 상호운용성과 표준화된 테스트 기능을 사용자에게 제공한다.</p><p>본 논문은 IEEE 1547-2018의 상호운용성 기술올 준수하는 스마트 인버터 기능 중 Volt-var 제어와 Frequency-watt 제어 알고리즘을 제안하고, Power HILS 환경을 구축하여 형식시험 정확하고 반복되게 수행할 수 있는 자동화 및 표준화된 테스트 플랫폼을 개발하였다. 제안 한 방식은 IEEE 1547-2018의 상호운용성 표준을 만족하기 위하여 Volt-var curve와 Frequency-watt curve 를 상위로부터 설정할 수 있도록 하며, Enable logic block올 퉁해 각 기능의 Enable 신호의 시점을 상위 지령에 따라 제어할 수 있도록 한다. 또한, Power HILS (Hardware-in-the-Loop Simulation)를 활용하여 IEEE Std 1547.1-2020 표준에 따른 해당 기능들의 형식시험을 통한 성능 검증을 수행한다.</p><p>Power HILS 환경 테스트 플랫폼을 통해 Volt-var 제어와 Frequency-watt 제어에 대한 형식시험을 수행하였다. 형식시험 수행 결과 주어진 전압 및 주파수 변화량에 따라 Volt-var 제어와 Frequency-watt 제어가 정상적으로 동작하여 스마트 인버터의 유효전력 및 무효전력이 제어됨을 확인하였으며, 측정 결과 일정 정상 범위 내에 위치하였다. 이에 따라. IEEE Std 1547.1-2020에 명시된 표준 형식시험을 전부 만족함을 검증하였다.</p>\n",
      "--------------------\n",
      "label: 전력시스템이 분산전원의 수용성을 높이기 위해 상호운용성 표준을 준수하도록 해당 기능의 curve를 상위로부터 설정할 수 있도록 하는 등 계통 연계기준을 강화하고 있다. 전 세계적으로 기후위기 극복을 위한 화셕연료 기반의 발전원 가동올 줄이고 재생에너지, ESs 등 분산자원의 보급률을 높이려는 옴직임이 활발하다. 최근 I시스템과 분산자원간의 연계 기준 및 상호운용성 기술 사양에 대한 표준을 자세하게 제시하였으며, 이를 의무화하려는 시도가 늘어나고 있다. 해외의 분산자원의 안정성 증대를 위해 스마트인버터 계통지원기능 보유 의무화를 추진 중에 있는 가운데, 국내에서도 시험과 검증에 대한 규정이 강화되어 표준 만족여부 확인을 위한 테스트 플랫폼 개발이 중요해지고 있다. 상호운용성 기술올 준수하는 스마트 인버터 기능 중 Volt-var 제어 알고리즘과 Power HILS 환경을 구축하여 형식시험 정확하고 반복되게 수행할 수 있는 자동화 및 표준화된 테스트 플랫폼을 개발했다. Power HILS 환경 테스트 플랫폼을 통해 형식시험 수행 결과 주어진 전압 및 주파수 변화량에 따라 Volt-var 제어와 Frequency·wat트제어가 정상적으로 동작하여 스마트 인버터의 유효전력이 제어되는 것을 확인하였다. Power HILS 환경 테스트 플랫폼을 통해 형식시험 수행 결과 주어진 전압 및 주파수 변화량에 따라 Volt-var 제어와 Frequency·wat트제어가 정상적으로 동작하여 스마트 인버터의 유효전력이 제어되는 것을 확인하였다.\n",
      "--------------------\n",
      "output: 전력시스템의 신뢰성을 보장함으로써 무분별한 분산전원의 증가에 따른 전력시스템의 신뢰성 및 안정도 하락을 심각하게 고려하고 있다. 최근 미국에서는 무분별한 분산전원의 증가에 따른 전력시스템의 신뢰성 및 안정도 하락을 심각하게 고려하고 있다. 최근 미국에서는 무분별한 분산전원의 증가에 따른 전력시스템의 신뢰성 및 안정도 하락을 심각하게 고려하고 있다. 최근 미국에서는 무분별한 분산전원의 증가에 따른 전력시스템의 신뢰성 및 안정도 하락을 심각하게 고려하고 있다.\n",
      "rouge-l f1 score: 10.383747178329571\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#높게 : 36번, 90번\n",
    "#낮게 : 96번, 17번\n",
    "summary_model.model.eval().to(device)\n",
    "i= 17 #random.seed(0)\n",
    "result = jdata[i]['refine_data'] #data['sentences'][i][0]\n",
    "print('input:',result)\n",
    "print('--------------------')\n",
    "print('label:',jdata[i]['summary'])\n",
    "print('--------------------')\n",
    "inputs = result\n",
    "#label_token = tokenizer(jdata[i]['summary'])['input_ids']\n",
    "\n",
    "#print(inputs)\n",
    "batch = tokenizer(inputs, return_tensors='pt', max_length=1024, truncation=True)\n",
    "#print('length:',len(batch['input_ids'][0]))\n",
    "len_sum = int(len(batch['input_ids'][0])*0.3)\n",
    "# print(len_sum)\n",
    "batch = batch.to(device)\n",
    "generated_ids = summary_model.model.generate(batch['input_ids'],max_length=len_sum)#.squeeze().tolist()#, num_beams=2, max_length=1024)#, no_repeat_ngram_size=2)\n",
    "result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "# print('--------------------')\n",
    "# print('len_output:',len(generated_ids[0]))\n",
    "print('output:',result[0])\n",
    "print('rouge-l f1 score:',df.iloc[i].item())\n",
    "print('--------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5b668ea6-fb71-4b05-af3f-e56d86daf132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def lst_lcs(lst1, lst2):\n",
    "#     dp = [[0]*(len(lst2)) for i in range(len(lst1))]\n",
    "    \n",
    "#     for i in range(1,len(lst1)):\n",
    "#         for j in range(1,len(lst2)):\n",
    "#             if lst1[i] == lst2[j]:\n",
    "#                 dp[i][j] = dp[i-1][j-1]+1\n",
    "#             else :\n",
    "#                 dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
    "#     return dp[-1][-1]\n",
    "            \n",
    "\n",
    "# def rouge_l_F1(truth, pred):\n",
    "    \n",
    "#     lcs_len = lst_lcs(truth, pred)\n",
    "    \n",
    "#     if (len(pred) == 0) or (len(truth) == 0):\n",
    "#         return int(pred == truth)\n",
    "#     if  lcs_len == 0:\n",
    "#         return 0    \n",
    "    \n",
    "#     precision = lcs_len/len(truth)\n",
    "#     recall = lcs_len/len(pred)\n",
    "    \n",
    "#     f1 = (2 * precision * recall)/(precision + recall)\n",
    "    \n",
    "#     return f1\n",
    "\n",
    "# my_score = []\n",
    "# summary_model.model.eval().to(device)\n",
    "# for i in range(10):\n",
    "#     #random.seed(0)\n",
    "#     result = jdata[i]['refine_data'] #data['sentences'][i][0]\n",
    "#     # print('input:',result)\n",
    "#     # print('--------------------')\n",
    "#     # print('label: ',jdata[i]['summary'])\n",
    "#     # print('--------------------')\n",
    "#     inputs = result\n",
    "#     label_token = tokenizer(jdata[i]['summary'])['input_ids']\n",
    "    \n",
    "#     #print(inputs)\n",
    "#     batch = tokenizer(inputs, return_tensors='pt', max_length=1024, truncation=True)\n",
    "#     #print('length:',len(batch['input_ids'][0]))\n",
    "#     len_sum = int(len(batch['input_ids'][0])*0.3)\n",
    "#     #print(len_sum)\n",
    "#     # print(batch['input_ids'].shape)\n",
    "#     batch = batch.to(device)\n",
    "#     generated_ids = summary_model.model.generate(batch['input_ids'],max_length=len_sum)#.squeeze().tolist()#, num_beams=2, max_length=1024)#, no_repeat_ngram_size=2)\n",
    "#     result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "#     # print('--------------------')\n",
    "#     # # print('len_output:',len(generated_ids[0]))\n",
    "#     # print('output: ',result[0])\n",
    "#     # print('--------------------')\n",
    "    \n",
    "# # scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "# # scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "# #                       'The quick brown dog jumps on the log.')\n",
    "#     # print(label_token)\n",
    "#     # print(generated_ids)\n",
    "#     my_score.append(rouge_l_F1(label_token,generated_ids.squeeze().tolist()))\n",
    "# print(sum(my_score)/len(my_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_LM",
   "language": "python",
   "name": "py36_lm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
